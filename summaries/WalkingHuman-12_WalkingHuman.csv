Steps,Policy/Entropy,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss
10000,1.4188832,0.0002970105,21.21562634395489,54.08791208791209,0.013619175,21.12812912925172,8.15686,0.33407396
20000,1.4186125,0.00029099797,21.615566195868045,54.644444444444446,0.64311284,21.743430238548253,6.6288667,0.28531292
30000,1.4183205,0.00028500194,21.056731423984424,53.79120879120879,0.9345294,21.028327162449177,5.727915,0.3030128
40000,1.4179952,0.00027900166,22.99808478523175,54.72222222222222,1.0469851,22.944659365879165,5.6435413,0.27879387
50000,1.4179467,0.00027299987,22.909371783898372,51.204188481675395,1.242416,22.936056402965367,5.3602586,0.3343716
60000,1.4174874,0.00026700803,24.803555927942423,51.36649214659686,1.3743765,24.787221648930256,5.6669865,0.34861708
70000,1.416817,0.00026100548,24.867336702780378,47.795121951219514,1.4949237,24.94679551938685,6.266778,0.38617483
80000,1.4164492,0.00025500104,25.514092897745787,48.07843137254902,1.5709603,25.327620424476326,6.5399523,0.383385
90000,1.4161327,0.00024898382,25.52348496185897,46.382075471698116,1.616535,25.611947168156785,6.285489,0.44841617
100000,1.4155267,0.00024298225,25.541059981953975,44.461187214611876,1.8102567,25.54331435895946,6.8888464,0.44048002
110000,1.415095,0.0002370037,25.81929799559591,45.395348837209305,1.8037215,25.839893758019734,6.6410418,0.41872537
120000,1.4145746,0.00023101113,26.27226030523095,44.45,1.8517786,26.264822979406876,7.075001,0.4325313
