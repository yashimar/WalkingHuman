Steps,Policy/Entropy,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss
2000,1.418976,0.00029940085,-6.852031420254295,3.8265060240963855,0.03150168,-6.8511515003471555,16.489017,1.933502
4000,1.4192704,0.0002982001,-6.761344330880769,3.6488372093023256,0.12249111,-6.761165549311527,16.848406,2.0553305
6000,1.4193842,0.00029700063,-6.844415992448928,3.6166281755196303,0.13743678,-6.84280528620264,17.338411,2.1228516
8000,1.4195724,0.0002958009,-6.819583236415028,3.7642857142857142,0.06997663,-6.823013554868244,16.776375,2.033287
