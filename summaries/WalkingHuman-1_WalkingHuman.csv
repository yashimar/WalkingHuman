Steps,Policy/Entropy,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss
2000,1.4191358,0.0002994003,-5.2650315536488055,2.6484517304189437,-0.16355918,-5.267084444308803,12.248888,2.4913285
4000,1.4201581,0.0002982,-5.3461135309418575,2.639344262295082,-0.14338008,-5.3450456916308795,11.57566,2.4718652
6000,1.4213068,0.00029700054,-5.3737912831470185,2.5906642728904847,-0.11658386,-5.37320460087521,12.481831,2.5176942
8000,1.4222076,0.0002958003,-5.2338351428960825,2.6514598540145986,-0.11630159,-5.234233403075351,13.42562,2.1509626
